trigger:
- none

pool:
  vmImage: 'windows-latest'

stages:
  - stage: Test
    displayName: Tst
    jobs:
      - deployment: Deploy
        displayName: Deploy Data Pipeline Codes
        environment: Tst
        variables:          
          - group: Common
          - group: Tst
        strategy:
          runOnce:
            deploy:
              steps:
              - checkout: self              
              - task: NodeTool@0
                displayName: 'Pre-requisite for ADF build: Install Node.js'
                inputs:
                  versionSpec: '10.x'                
              - task: Npm@1
                displayName: 'Pre-requisite for ADF build: Install npm package'
                inputs:
                  command: 'install'
                  verbose: true             
              - task: Npm@1
                displayName: 'Validate and Build ADF ARM templates'
                inputs:
                  command: 'custom'
                  customCommand: 'run build export Platform/DataFactory /subscriptions/$(Environment.Subscription.Id)/resourceGroups/AssetVoyage-Dev-1.0-001-Platform-rg/providers/Microsoft.DataFactory/factories/AssetVoyage-Dev-001-DF "DataFactoryArmTemplate"'
              - task: AzurePowerShell@5
                displayName: 'Stop ADF Triggers before deployment'
                inputs:
                  azureSubscription: 'sp-devops-pipeline'
                  ScriptPath: '$(Build.Repository.LocalPath)/DataFactoryArmTemplate/PrePostDeploymentScript.ps1'
                  ScriptArguments: '-armTemplate "$(Build.Repository.LocalPath)/DataFactoryArmTemplate/ARMTemplateForFactory.json" -ResourceGroupName $(Environment.ResourceGroup.Name) -DataFactoryName $(Integration.DataFactory.Name) -predeployment $true -deleteDeployment $false'
                  azurePowerShellVersion: LatestVersion           
              - task: AzureResourceManagerTemplateDeployment@3
                displayName: 'Deploy ADF pipelines / dataset / linked services'
                inputs:
                  deploymentScope: 'Resource Group'
                  azureResourceManagerConnection: 'sp-devops-pipeline'
                  subscriptionId: '$(Environment.Subscription.Id)'
                  action: 'Create Or Update Resource Group'
                  resourceGroupName: '$(Environment.ResourceGroup.Name)'
                  location: '$(Environment.ResourceGroup.Location)'
                  csmFile: '$(Build.Repository.LocalPath)/DataFactoryArmTemplate/ARMTemplateForFactory.json'
                  csmParametersFile: '$(Build.Repository.LocalPath)/DataFactoryArmTemplate/ARMTemplateParametersForFactory.json'
                  overrideParameters: '
                    -factoryName $(Integration.DataFactory.Name) 
                    -LS_AzSQLDB_connectionString "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=$(Database.SQLServer.Name).database.windows.net;Initial Catalog=$(Database.SQLDatabase.Name)" 
                    -LS_Adls_properties_typeProperties_url "https://$(Storage.DataLake.Name).dfs.core.windows.net" 
                    -LS_Databricks_properties_typeProperties_domain "https://$(Integration.Databricks.URL).azuredatabricks.net" 
                    -LS_Databricks_properties_typeProperties_workspaceResourceId "/subscriptions/$(Environment.Subscription.Id)/resourceGroups/$(Environment.ResourceGroup.Name)/providers/Microsoft.Databricks/workspaces/$(Integration.Databricks.Name)" 
                    -LS_Databricks_properties_typeProperties_newClusterNodeType "$(Integration.Databricks.JobClusterNodeType)" 
                    -LS_Databricks_properties_typeProperties_newClusterNumOfWorker "$(Integration.Databricks.NumOfWorker)" 
                    -LS_Databricks_properties_typeProperties_newClusterVersion "$(Integration.Databricks.JobClusterVersion)" 
                    -LS_KeyVault_properties_typeProperties_baseUrl "https://$(Security.KeyVault.Name).vault.azure.net/" 
                    -LS_Maximo_properties_typeProperties_connectionString_secretName "maximo-ods-connection-string"
                    -TR_Tumbling_Master_AZ_SQL_To_ADLS_Conformed_properties_pipeline_parameters_Tumbling_StartTime "@{trigger().outputs.windowStartTime}"
                    -TR_Tumbling_Master_AZ_SQL_To_ADLS_Conformed_properties_pipeline_parameters_Tumbling_EndTIme "@{trigger().outputs.windowEndTime}"
                    -TR_Refresh_PBI_Dataset_properties_PL_Driver_Refresh_PBI_Datasets_parameters_KeyVaultName "$(Security.KeyVault.Name).vault.azure.net"
                    -TR_Refresh_PBI_Dataset_properties_PL_Driver_Refresh_PBI_Datasets_parameters_WorkspaceName "$(Power.BI.Workspace)"'
                  deploymentMode: 'Incremental'
              - task: AzurePowerShell@5
                displayName: 'Start ADF Triggers'
                inputs:
                  azureSubscription: 'sp-devops-pipeline'
                  ScriptPath: '$(Build.Repository.LocalPath)/DataFactoryArmTemplate/PrePostDeploymentScript.ps1'
                  ScriptArguments: '-armTemplate "$(Build.Repository.LocalPath)/DataFactoryArmTemplate/ARMTemplateForFactory.json" -ResourceGroupName $(Environment.ResourceGroup.Name) -DataFactoryName $(Integration.DataFactory.Name) -predeployment $false -deleteDeployment $true'
                  azurePowerShellVersion: LatestVersion
              - task: AzureCLI@2
                displayName: 'Upload files into Data Lake'
                inputs:
                  azureSubscription: 'sp-devops-pipeline'
                  scriptType: 'ps'
                  scriptLocation: 'inlineScript'
                  inlineScript: |                                        
                    az storage blob upload-batch -s "Platform/DataLake/datafactory-config" -d "raw/metadata/datafactory-config" --account-name $(DataLake.Name) --auth-mode login
              - task: databricksDeployScripts@0
                displayName: 'Deploy Databricks notebooks'
                inputs:
                  authMethod: 'bearer'
                  bearerToken: '$(Integration.Databricks.Token)'
                  region: '$(Integration.Databricks.URL)'
                  localPath: 'Platform/Databricks/platform'
                  databricksPath: '/platform'
              - task: databricksDeployDBFSFilesTask@0
                displayName: 'Deploy Databricks files into Databricks File System (DBFS)'
                inputs:
                  authMethod: 'bearer'
                  bearerToken: '$(Integration.Databricks.Token)'
                  region: '$(Integration.Databricks.URL)'
                  LocalRootFolder: 'Platform/Databricks/platform-config'  
                  TargetLocation: '/platform-config'
              - task: VSBuild@1
                displayName: 'Build Visual Studio solution file'
                inputs:
                  solution: 'Platform/Database/*.sln'
                  platform: 'Any CPU'
                  configuration: 'Release'
              - task: AzureCLI@2
                displayName: 'Get Access Token for Dacpac deployment'
                inputs:
                  azureSubscription: 'sp-devops-pipeline'
                  scriptType: 'ps'
                  scriptLocation: 'inlineScript'
                  inlineScript: |
                    $token= & az account get-access-token --resource=https://database.windows.net/ --query accessToken
                         Write-Output("##vso[task.setvariable variable=SQLToken;]$token")
              - task: SqlAzureDacpacDeployment@1
                displayName: 'Publish Dacpac for Azure SQL DB'
                inputs:
                  azureSubscription: 'sp-devops-pipeline'
                  AuthenticationType: 'connectionString'
                  ConnectionString: 'Server=$(Database.SQLServer.Name).database.windows.net;Initial Catalog=$(Database.SQLDatabase.Name);Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;'
                  deployType: 'DacpacTask'
                  DeploymentAction: 'Publish'
                  DacpacFile: '$(System.DefaultWorkingDirectory)\Platform\Database\SpareParts_SSDT_01\bin\Release\SpareParts_SSDT_01.dacpac'
                  IpDetectionMethod: 'AutoDetect'
                  AdditionalArguments: '/AccessToken:$(SQLToken) /p:BlockOnPossibleDataLoss=false /p:DropStatisticsNotInSource=true'